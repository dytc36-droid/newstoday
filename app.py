import streamlit as st
import feedparser
import urllib.parse
from datetime import datetime, timedelta

# --- 1. ì„¤ì • ë° ë””ìì¸ ---
st.set_page_config(page_title="News Today", layout="wide")
st.markdown("<style>.stApp { background-color: #f8f9fa; }</style>", unsafe_allow_html=True)

CATEGORIES = {
    "ê´€ê³„ì‚¬": {
        "icon": "ğŸ¢", 
        "keywords": ["ëŒ€ì„±ê³„ì „", "ëŒ€ì„±ì‚°ì—…", "ëŒ€ì„±ë¬¼ë¥˜ê±´ì„¤", "ëŒ€ì„±ì—ë„ˆì§€", "ëŒ€ì„±í™€ë”©ìŠ¤", "ëŒ€ì„±ì°½íˆ¬", "MCM"],
        "must_have": ["ëŒ€ì„±"] 
    },
    "ë„ì‹œê°€ìŠ¤": {"icon": "ğŸ”¥", "keywords": ["ì„œìš¸ë„ì‹œê°€ìŠ¤", "ë„ì‹œê°€ìŠ¤", "SCNG", "GRM", "GRES", "SCGS", "SCGG", "SCGLAB", "ê°€ìŠ¤ì•±", "ì—ìŠ¤ì”¨ì§€", "ì—ë„ˆì§€í†¡"]},
    "ì •ì±… Â· ê·œì œ": {"icon": "âš–ï¸", "keywords": ["ì‚°ì—…ë¶€ ì •ì±…", "ì „ê¸°ìš”ê¸ˆ", "ê°€ìŠ¤ìš”ê¸ˆ", "íƒ„ì†Œì •ì±…", "ê³µì •ìœ„", "ê¸ˆìœµìœ„", "êµ­íšŒ ì…ë²•", "ë‚´ë¶€ê±°ë˜", "ë¶€ë‹¹ê±°ë˜", "ì¼ê° ëª°ì•„ì£¼ê¸°"]},
    "ì—ë„ˆì§€": {"icon": "âš¡", "keywords": ["í•œì „", "ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ", "ì „ë ¥ê´€ë¦¬", "ì „ë ¥ì‹œì¥", "ì „ë ¥ë§", "ESS", "íƒ„ì†Œ", "ì „ë ¥ ë””ì§€í„¸", "ì—ë„ˆì§€ ê´€ë¦¬ ì‹œìŠ¤í…œ", "íƒœì–‘ê´‘", "ì „ê¸°ì°¨ ì¶©ì „"]},
    "IT": {"icon": "ğŸ’»", "keywords": ["AI", "IT", "ë¡œë´‡", "ë©”íƒ€ë²„ìŠ¤", "ë¹…í…Œí¬", "ì‚¬ë¬¼ì¸í„°ë„·", "ì±—GPT", "í”Œë«í¼", "iot", "o2o", "SAAS", "ë°ì´í„° ë¶„ì„", "ìµœì í™”", "ì˜ˆì¸¡"]},
    "ì¸ì  ë„¤íŠ¸ì›Œí¬": {
        "icon": "ğŸ¤", 
        "keywords": [
            "ê·€ëšœë¼ë¯¸", "êµì›", "ëŒ€ì‹ ì¦ê¶Œ", "ë™í™”ì•½í’ˆ", "ë¯¸ë˜ì•¤ì„œí•´ì—ë„ˆì§€", 
            "ì„±í˜¸ì „ì", "ì‚¼ì²œë¦¬", "ì˜ˆìŠ¤ì½”", "ì¹´ì¹´ì˜¤", "ì•„ì£¼í˜¸í…”ì•¤ë¦¬ì¡°íŠ¸", 
            "ì°¸í”„ë ˆ", "ì˜ì¹´", "ì”¨ì•¤ì‹œí‹°", "JB", "ì°¸ë¹›ê·¸ë£¹", "ì¤‘ì•™ì—ë„ˆë¹„ìŠ¤", "í•œìœ ", "GS ì— ë¹„ì¦ˆ",
            "ìµœì„±í™˜", "ì¥ì„ í•˜", "ì¥ë™í•˜", "ì–‘í™ì„", "ê¹€ì˜ì§„", "ë°•ì„±ì¬", "ì´ì€ì„ ", "êµ¬ë³¸í˜", "ìœ¤ë™í¬", "ë¬¸ìœ¤íšŒ", "ê¹€ì¬ìœ¤", "ë°•ì¬ìš±", "ê¹€ì˜ì„", "ì´í˜¸ì›…", "í•œìŠ¹í¬", "ë°•ì›ì„"
        ]
    }
}

if 'global_seen_titles' not in st.session_state:
    st.session_state.global_seen_titles = set()

# --- 2. ë‰´ìŠ¤ ìˆ˜ì§‘ í•¨ìˆ˜ ---
def fetch_news(cat_name, keywords):
    now = datetime.now()
    today_08 = now.replace(hour=8, minute=0, second=0, microsecond=0)
    
    # ì¸ì  ë„¤íŠ¸ì›Œí¬ëŠ” ë°ì´í„° í™•ë³´ë¥¼ ìœ„í•´ 3ì¼ì¹˜ ê²€ìƒ‰
    days_to_search = 3 if cat_name == "ì¸ì  ë„¤íŠ¸ì›Œí¬" else 1
    yesterday_08 = today_08 - timedelta(days=days_to_search)
    
    query = " OR ".join(keywords)
    encoded_query = urllib.parse.quote(f"({query}) after:{yesterday_08.strftime('%Y-%m-%d')} before:{today_08.strftime('%Y-%m-%d')}")
    
    feed = feedparser.parse(f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko")
    news_items = []

    for e in feed.entries:
        try:
            pub_time = datetime(*e.published_parsed[:6]) + timedelta(hours=9)
            if yesterday_08 <= pub_time < today_08:
                full_title = e.title.rsplit(' - ', 1)[0].strip()
                clean_title = "".join(full_title.split())
                
                if cat_name != "ê´€ê³„ì‚¬":
                    if any(word in full_title for word in CATEGORIES["ê´€ê³„ì‚¬"]["must_have"]):
                        continue 

                if clean_title not in st.session_state.global_seen_titles:
                    news_items.append({"title": full_title, "link": e.link, "source": e.source.get('title', 'ì–¸ë¡ ì‚¬'), "time": pub_time})
                    st.session_state.global_seen_titles.add(clean_title)
        except: continue
    return sorted(news_items, key=lambda x: x['time'], reverse=True)

# --- 3. í™”ë©´ ì¶œë ¥ ---
st.title("ğŸ“° News Today")
st.markdown(f"### ğŸ“… {datetime.now().strftime('%Yë…„ %mì›” %dì¼')} ({['ì›”','í™”','ìˆ˜','ëª©','ê¸ˆ','í† ','ì¼'][datetime.now().weekday()]}ìš”ì¼)")
st.write("---")

# ì£¼ìš” ê²½ì œ ì§€í‘œ ì„¹ì…˜ (ì¶”ê°€ëœ ë¶€ë¶„)
st.markdown("#### ğŸ“ˆ ì£¼ìš” ê²½ì œ ì§€í‘œ (ì‹¤ì‹œê°„ ë§í¬)")
m_cols = st.columns(4)
market_links = {
    "ğŸ“‰ KOSPI": "https://finance.naver.com/sise/sise_index.nhn?code=KOSPI",
    "ğŸ‡ºğŸ‡¸ S&P 500": "https://finance.naver.com/world/sise.naver?symbol=SPI@SPX",
    "ğŸ›¢ï¸ êµ­ì œìœ ê°€(WTI)": "https://finance.naver.com/marketindex/worldDailyQuote.naver?marketindexCd=OIL_CL&fdtc=2",
    "ğŸ’µ ì›/ë‹¬ëŸ¬ í™˜ìœ¨": "https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_USDKRW"
}

for i, (name, url) in enumerate(market_links.items()):
    with m_cols[i]:
        st.link_button(name, url, use_container_width=True)

st.write("")

# ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥
st.session_state.global_seen_titles = set()
display_order = [["ë„ì‹œê°€ìŠ¤", "ì •ì±… Â· ê·œì œ", "ì—ë„ˆì§€"], ["IT", "ì¸ì  ë„¤íŠ¸ì›Œí¬", "ê´€ê³„ì‚¬"]]

# ê´€ê³„ì‚¬ ì„ í–‰ ìˆ˜ì§‘
pre_fetched = {"ê´€ê³„ì‚¬": fetch_news("ê´€ê³„ì‚¬", CATEGORIES["ê´€ê³„ì‚¬"]["keywords"])}

for row in display_order:
    cols = st.columns(3)
    for i, cat_name in enumerate(row):
        with cols[i]:
            with st.container(border=True):
                st.markdown(f"#### {CATEGORIES[cat_name]['icon']} {cat_name}")
                with st.spinner(f'{cat_name} ìˆ˜ì§‘ ì¤‘...'):
                    res = pre_fetched["ê´€ê³„ì‚¬"] if cat_name == "ê´€ê³„ì‚¬" else fetch_news(cat_name, CATEGORIES[cat_name]['keywords'])
                
                with st.expander(f"ğŸ“Œ ì´ {len(res)}ê±´ì˜ ì†Œì‹", expanded=False):
                    if res:
                        for news in res:
                            st.markdown(f"**Â· [{news['title']}]({news['link']})**")
                            st.caption(f"ì¶œì²˜: {news['source']} | {news['time'].strftime('%H:%M')}")
                            st.write("")
                    else:
                        st.info("ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")